{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from torchvision import transforms \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripping(liste):\n",
    "    return [i.strip() for i in liste]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857c84bd07aa4f17a318b1c2d64255f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568755dc0bcd4bf29e7cc7ae94275df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252bd54a43074f64a095ca2c98d79895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.read_csv('data/over.csv',converters={'list_alle': lambda x: x[1:-1].strip('][').replace(\"'\",\"\").strip().split(','),\n",
    "'list_normen': lambda x: x[1:-1].strip('][').replace(\"'\",\"\").strip().split(','),\n",
    "'list_gesamt': lambda x: x[1:-1].strip('][').replace(\"'\",\"\").strip().split(',')\n",
    "})\n",
    "\n",
    "df['list_alle']=df['list_alle'].progress_apply(stripping)\n",
    "df['list_normen']=df['list_normen'].progress_apply(stripping)\n",
    "df['list_gesamt']=df['list_gesamt'].progress_apply(stripping)\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic_num</th>\n",
       "      <th>percent</th>\n",
       "      <th>list_alle</th>\n",
       "      <th>list_normen</th>\n",
       "      <th>list_gesamt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This blog is being posted due to the fact that...</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0.4414019715224534</td>\n",
       "      <td>[0.0, 0.0, 0.16700000000000004, 0.0, 0.021, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.055999999999999994, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So I have a big fucking interview tomorrow for...</td>\n",
       "      <td>Student</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0.3124452234881683</td>\n",
       "      <td>[0.176, 0.0, 0.083, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.0, 0.849, 0.0, 0.0, 0.023, 0.0, 0.153000000...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was reminded just now of the time Ashley and...</td>\n",
       "      <td>Student</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>0.20397382322794297</td>\n",
       "      <td>[1.863999999999999, 0.05, 0.5950000000000003, ...</td>\n",
       "      <td>[0.0, 5.121999999999999, 0.0, 0.0, 0.417000000...</td>\n",
       "      <td>[0.004, 0.0, 0.0, 0.018000000000000002, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was checking up on my cousin Dylan and Fanni...</td>\n",
       "      <td>Student</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>0.2786579683131407</td>\n",
       "      <td>[0.0, 0.0, 0.08300000000000002, 0.08, 0.0, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.069, 0.0, 0.042, 0.0, 0...</td>\n",
       "      <td>[0.0, 0.0, 0.003, 0.006, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for the NME interview click urlLink part 1 and...</td>\n",
       "      <td>Student</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>0.9468664850136239</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014, 0.0, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    topic  gender  age  \\\n",
       "0  This blog is being posted due to the fact that...  Student    male   14   \n",
       "1  So I have a big fucking interview tomorrow for...  Student    male   15   \n",
       "2  I was reminded just now of the time Ashley and...  Student  female   17   \n",
       "3  I was checking up on my cousin Dylan and Fanni...  Student  female   23   \n",
       "4  for the NME interview click urlLink part 1 and...  Student  female   23   \n",
       "\n",
       "  topic_num              percent  \\\n",
       "0         7   0.4414019715224534   \n",
       "1        20   0.3124452234881683   \n",
       "2        27  0.20397382322794297   \n",
       "3        20   0.2786579683131407   \n",
       "4        31   0.9468664850136239   \n",
       "\n",
       "                                           list_alle  \\\n",
       "0  [0.0, 0.0, 0.16700000000000004, 0.0, 0.021, 0....   \n",
       "1  [0.176, 0.0, 0.083, 0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "2  [1.863999999999999, 0.05, 0.5950000000000003, ...   \n",
       "3  [0.0, 0.0, 0.08300000000000002, 0.08, 0.0, 0.0...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                         list_normen  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.055999999999999994, 0.0...   \n",
       "1  [0.0, 0.849, 0.0, 0.0, 0.023, 0.0, 0.153000000...   \n",
       "2  [0.0, 5.121999999999999, 0.0, 0.0, 0.417000000...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.069, 0.0, 0.042, 0.0, 0...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014, 0.0, 0.0...   \n",
       "\n",
       "                                         list_gesamt  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0...  \n",
       "2  [0.004, 0.0, 0.0, 0.018000000000000002, 0.0, 0...  \n",
       "3  [0.0, 0.0, 0.003, 0.006, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "over=pd.DataFrame(data=df['list_alle'].tolist(),columns=[f'Topic_{x}' for x in range(len(df['list_alle'][0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>Topic_6</th>\n",
       "      <th>Topic_7</th>\n",
       "      <th>Topic_8</th>\n",
       "      <th>Topic_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_28</th>\n",
       "      <th>Topic_29</th>\n",
       "      <th>Topic_30</th>\n",
       "      <th>Topic_31</th>\n",
       "      <th>Topic_32</th>\n",
       "      <th>Topic_33</th>\n",
       "      <th>Topic_34</th>\n",
       "      <th>Topic_35</th>\n",
       "      <th>Topic_36</th>\n",
       "      <th>Topic_37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16700000000000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15600000000000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.863999999999999</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5950000000000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14800000000000002</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08300000000000002</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41700000000000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Topic_0 Topic_1              Topic_2 Topic_3 Topic_4 Topic_5  \\\n",
       "0                0.0     0.0  0.16700000000000004     0.0   0.021     0.0   \n",
       "1              0.176     0.0                0.083     0.0     0.0     0.0   \n",
       "2  1.863999999999999    0.05   0.5950000000000003     0.0     0.0   0.189   \n",
       "3                0.0     0.0  0.08300000000000002    0.08     0.0   0.056   \n",
       "4                0.0     0.0                  0.0     0.0     0.0     0.0   \n",
       "\n",
       "  Topic_6              Topic_7 Topic_8 Topic_9  ... Topic_28  \\\n",
       "0     0.0                0.403     0.0   0.022  ...      0.0   \n",
       "1     0.0                  0.0     0.0     0.0  ...      0.0   \n",
       "2   0.216                  0.0     0.0     0.0  ...    0.102   \n",
       "3     0.0  0.41700000000000004     0.0     0.0  ...      0.0   \n",
       "4     0.0                  0.0     0.0     0.0  ...      0.0   \n",
       "\n",
       "              Topic_29 Topic_30 Topic_31 Topic_32 Topic_33 Topic_34  \\\n",
       "0  0.15600000000000003      0.0      0.0    0.022      0.0      0.0   \n",
       "1                  0.0      0.0      0.0    0.016    0.087    0.008   \n",
       "2                  0.0     0.07      0.0      0.0    0.033      0.0   \n",
       "3                  0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4                  0.0      0.0     1.39      0.0      0.0      0.0   \n",
       "\n",
       "              Topic_35 Topic_36 Topic_37  \n",
       "0                  0.0      0.0      0.0  \n",
       "1                0.112      0.0      0.0  \n",
       "2  0.14800000000000002    0.064    0.136  \n",
       "3                0.112    0.017      0.0  \n",
       "4                  0.0      0.0     0.04  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = over.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>Topic_6</th>\n",
       "      <th>Topic_7</th>\n",
       "      <th>Topic_8</th>\n",
       "      <th>Topic_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic_28</th>\n",
       "      <th>Topic_29</th>\n",
       "      <th>Topic_30</th>\n",
       "      <th>Topic_31</th>\n",
       "      <th>Topic_32</th>\n",
       "      <th>Topic_33</th>\n",
       "      <th>Topic_34</th>\n",
       "      <th>Topic_35</th>\n",
       "      <th>Topic_36</th>\n",
       "      <th>Topic_37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845083</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.980038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992926</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.826281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969144</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.961614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923006</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977560</td>\n",
       "      <td>0.96396</td>\n",
       "      <td>0.999614</td>\n",
       "      <td>0.856410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.593457</td>\n",
       "      <td>0.966125</td>\n",
       "      <td>0.448052</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945407</td>\n",
       "      <td>0.92925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987879</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.98633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.810256</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923006</td>\n",
       "      <td>0.91658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983824</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.870658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.856410</td>\n",
       "      <td>0.994097</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic_0   Topic_1   Topic_2  Topic_3   Topic_4   Topic_5  Topic_6  \\\n",
       "0  1.000000  1.000000  0.845083  1.00000  0.980038  1.000000  1.00000   \n",
       "1  0.961614  1.000000  0.923006  1.00000  1.000000  1.000000  1.00000   \n",
       "2  0.593457  0.966125  0.448052  1.00000  1.000000  0.945407  0.92925   \n",
       "3  1.000000  1.000000  0.923006  0.91658  1.000000  0.983824  1.00000   \n",
       "4  1.000000  1.000000  1.000000  1.00000  1.000000  1.000000  1.00000   \n",
       "\n",
       "    Topic_7  Topic_8   Topic_9  ...  Topic_28  Topic_29  Topic_30  Topic_31  \\\n",
       "0  0.875000      1.0  0.992926  ...   1.00000  0.826281  1.000000  1.000000   \n",
       "1  1.000000      1.0  1.000000  ...   1.00000  1.000000  1.000000  1.000000   \n",
       "2  1.000000      1.0  1.000000  ...   0.92522  1.000000  0.987879  1.000000   \n",
       "3  0.870658      1.0  1.000000  ...   1.00000  1.000000  1.000000  1.000000   \n",
       "4  1.000000      1.0  1.000000  ...   1.00000  1.000000  1.000000  0.913043   \n",
       "\n",
       "   Topic_32  Topic_33  Topic_34  Topic_35  Topic_36  Topic_37  \n",
       "0  0.969144   1.00000  1.000000  1.000000  1.000000  1.000000  \n",
       "1  0.977560   0.96396  0.999614  0.856410  1.000000  1.000000  \n",
       "2  1.000000   0.98633  1.000000  0.810256  0.977778  0.875000  \n",
       "3  1.000000   1.00000  1.000000  0.856410  0.994097  1.000000  \n",
       "4  1.000000   1.00000  1.000000  1.000000  1.000000  0.963235  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "for cols in over.columns:\n",
    "    over[cols] = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ct = ColumnTransformer([\n",
    "        ('somename', StandardScaler(), [x for x in over.columns])\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "columns_df=ct.fit_transform(over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.69923967, -0.42413485,  0.01777494, -0.23476964,  0.07850612,\n",
       "        -0.35338029, -0.29028851,  1.87495284, -0.28890936,  0.06836893,\n",
       "        -0.25390775, -0.35656502, -0.43895174, -0.350449  , -0.28958754,\n",
       "        -0.28931603, -0.45513628, -0.22033514, -0.39279358, -0.33107604,\n",
       "        -0.72484534, -0.2757282 , -0.38179668, -0.21600785, -0.69222581,\n",
       "        -0.39818937, -0.29866706, -0.67227126, -0.38197017,  4.4987989 ,\n",
       "        -0.27601024, -0.42915718,  0.2026593 , -0.40476083, -0.16318384,\n",
       "        -0.3358712 , -0.27033806, -0.31134044],\n",
       "       [-0.19635853, -0.42413485, -0.49935331, -0.23476964, -0.3939983 ,\n",
       "        -0.35338029, -0.29028851, -0.30878177, -0.28890936, -0.2787965 ,\n",
       "        -0.25390775, -0.35656502, -0.43895174, -0.56373392, -0.28958754,\n",
       "        -0.28931603, -0.30073974, -0.22033514, -0.39279358, -0.33107604,\n",
       "         0.42287309,  1.96268901, -0.38179668, -0.21600785, -0.31553623,\n",
       "         0.80053995, -0.29866706, -0.6686314 , -0.38197017, -0.31870598,\n",
       "        -0.27601024, -0.42915718,  0.02696137,  1.12530509, -0.15418858,\n",
       "         2.15871383, -0.27033806, -0.31134044],\n",
       "       [ 4.62672881,  0.25388898,  2.65266651, -0.23476964, -0.3939983 ,\n",
       "         3.02301336,  1.39339156, -0.30878177, -0.28890936, -0.2787965 ,\n",
       "        -0.25390775,  1.60697044, -0.43895174,  0.4315957 , -0.28958754,\n",
       "        -0.28931603,  0.82899104, -0.22033514, -0.39279358,  0.71650631,\n",
       "         1.99394349, -0.2757282 ,  2.70610173, -0.21600785,  2.27943644,\n",
       "         4.56413668, -0.29866706,  4.03588267,  1.19415305, -0.31870598,\n",
       "         0.25650949, -0.42915718, -0.44156642,  0.175609  , -0.16318384,\n",
       "         2.96054473,  0.62805094,  2.57909091],\n",
       "       [-0.69923967, -0.42413485, -0.49935331,  1.38870942, -0.3939983 ,\n",
       "         0.64703264, -0.29028851,  1.95081459, -0.28890936, -0.2787965 ,\n",
       "        -0.25390775, -0.35656502,  5.87000425, -0.56373392, -0.28958754,\n",
       "        -0.19591038, -0.45890205, -0.22033514, -0.39279358, -0.33107604,\n",
       "         0.23775722, -0.2757282 , -0.38179668, -0.21600785, -0.64200053,\n",
       "        -0.39818937, -0.29866706, -0.046216  , -0.38197017, -0.31870598,\n",
       "        -0.27601024, -0.42915718, -0.44156642, -0.40476083, -0.16318384,\n",
       "         2.15871383, -0.03170349, -0.31134044],\n",
       "       [-0.69923967, -0.42413485, -1.01032527, -0.23476964, -0.3939983 ,\n",
       "        -0.35338029, -0.29028851, -0.30878177, -0.28890936, -0.2787965 ,\n",
       "        -0.25390775, -0.35656502, -0.43895174, -0.56373392, -0.28958754,\n",
       "        -0.28931603, -0.64342475, -0.22033514, -0.39279358, -0.33107604,\n",
       "        -0.72484534, -0.2757282 , -0.38179668, -0.21600785, -0.87638516,\n",
       "        -0.39818937, -0.29866706, -0.67227126, -0.38197017, -0.31870598,\n",
       "        -0.27601024,  1.27416768, -0.44156642, -0.40476083, -0.16318384,\n",
       "        -0.3358712 , -0.27033806,  0.53878643],\n",
       "       [-0.69923967, -0.42413485, -0.80101146, -0.23476964, -0.3939983 ,\n",
       "        -0.35338029, -0.29028851, -0.30878177, -0.28890936, -0.2787965 ,\n",
       "        -0.25390775, -0.35656502, -0.43895174, -0.56373392, -0.28958754,\n",
       "        -0.28931603, -0.25931628, -0.22033514, -0.39279358, -0.33107604,\n",
       "        -0.72484534, -0.2757282 , -0.38179668, -0.21600785, -0.82615988,\n",
       "        -0.39818937, -0.29866706, -0.046216  , -0.38197017, -0.31870598,\n",
       "         1.81603156, -0.42915718, -0.44156642, -0.40476083, -0.16318384,\n",
       "        -0.3358712 , -0.27033806, -0.31134044],\n",
       "       [ 1.12370447, -0.42413485,  2.17247599,  0.65814384,  1.72102147,\n",
       "        -0.35338029, -0.29028851, -0.30878177, -0.28890936, -0.15255453,\n",
       "         0.85032918,  5.71915582, -0.43895174,  1.81794768,  0.51313289,\n",
       "        -0.28931603,  2.64409184, -0.22033514, -0.39279358, -0.33107604,\n",
       "         1.31464871,  0.85434651,  1.16215253,  3.24335449,  1.90274686,\n",
       "        -0.39818937, -0.29866706,  0.48338307, -0.38197017, -0.31870598,\n",
       "        -0.27601024, -0.42915718,  1.87178957, -0.24647815, -0.13282483,\n",
       "        -0.3358712 , -0.27033806, -0.31134044],\n",
       "       [ 0.71225627, -0.34277199,  0.38715226, -0.23476964, -0.3939983 ,\n",
       "        -0.35338029, -0.29028851, -0.30878177, -0.28890936, -0.2787965 ,\n",
       "        -0.25390775, -0.35656502,  0.80946358, -0.01274788, -0.28958754,\n",
       "        -0.28931603,  0.59551335, -0.22033514,  1.89097749, -0.33107604,\n",
       "        -0.15179097, -0.2757282 , -0.38179668, -0.21600785,  0.41273029,\n",
       "        -0.30931806, -0.29866706,  0.53252113, -0.38197017, -0.31870598,\n",
       "        -0.27601024, -0.42915718,  2.80884516,  1.12530509, -0.16318384,\n",
       "        -0.3358712 , -0.27033806, -0.31134044],\n",
       "       [ 0.81226104, -0.42413485, -0.76407372, -0.23476964, -0.3939983 ,\n",
       "        -0.35338029, -0.29028851, -0.30878177, -0.28890936, -0.2787965 ,\n",
       "        -0.25390775, -0.35656502, -0.43895174, -0.52818643, -0.28958754,\n",
       "        -0.28931603, -0.25555051, -0.22033514, -0.39279358, -0.33107604,\n",
       "        -0.33529715, -0.2757282 ,  1.16215253, -0.21600785, -0.24019831,\n",
       "        -0.39818937,  2.29130643, -0.47207917, -0.38197017, -0.31870598,\n",
       "        -0.27601024, -0.42915718, -0.44156642, -0.40476083, -0.16318384,\n",
       "        -0.3358712 , -0.27033806, -0.31134044],\n",
       "       [ 0.11508491, -0.42413485,  0.43024629, -0.23476964, -0.3939983 ,\n",
       "        -0.35338029, -0.29028851, -0.30878177, -0.28890936, -0.2787965 ,\n",
       "        -0.25390775, -0.35656502, -0.43895174, -0.56373392, -0.28958754,\n",
       "        -0.28931603, -0.63589321, -0.22033514, -0.39279358, -0.33107604,\n",
       "        -0.10832899, -0.2757282 , -0.38179668, -0.21600785, -0.57503349,\n",
       "        -0.39818937, -0.29866706,  1.20953437, -0.38197017, -0.31870598,\n",
       "        -0.27601024, -0.42915718,  1.25684683, -0.40476083, -0.16318384,\n",
       "        -0.3358712 , -0.27033806, -0.31134044]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6992, -0.4241,  0.0178,  ..., -0.3359, -0.2703, -0.3113],\n",
       "        [-0.1964, -0.4241, -0.4994,  ...,  2.1587, -0.2703, -0.3113],\n",
       "        [ 4.6267,  0.2539,  2.6527,  ...,  2.9605,  0.6281,  2.5791],\n",
       "        ...,\n",
       "        [-0.6392, -0.4241, -0.3885,  ..., -0.3359, -0.2703, -0.3113],\n",
       "        [-0.6992, -0.4241, -1.0103,  ..., -0.3359, -0.0317, -0.3113],\n",
       "        [-0.0649, -0.4241, -0.0376,  ..., -0.3359, -0.2703,  1.3252]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(columns_df).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> neuronales netzt --> den tensor input --> mit convid 2--> basiernd davon ergebnisse bekommen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic_num'] = pd.factorize(df['topic'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[0;32m----> 2\u001b[0m scaler\u001b[39m.\u001b[39mfit_transform(df[\u001b[39m'\u001b[39;49m\u001b[39mtopic_num\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mtolist()\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(df['topic_num'].tolist().reshape(1, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['topic_num']\n",
    "features = df[col_names]\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "scaled_features = pd.DataFrame(features, columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.688194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.688194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.688194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.688194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.688194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_num\n",
       "0  -1.688194\n",
       "1  -1.688194\n",
       "2  -1.688194\n",
       "3  -1.688194\n",
       "4  -1.688194"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.6882)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(scaled_features['topic_num'].tolist())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "    self.fc1 = nn.Linear(128*28*28, 128)\n",
    "    self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.relu(self.conv1(x))\n",
    "    x = torch.relu(self.conv2(x))\n",
    "    x = torch.relu(self.conv3(x))\n",
    "    x = x.view(-1, 128*28*28)\n",
    "    x = torch.relu(self.fc1(x))\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "\n",
    "# create a tensor input list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalNeuralNetwork(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=100352, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvolutionalNeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_list=torch.from_numpy(columns_df).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19500"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(columns_df).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "n_epochs = 5\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=momentum)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(columns_df,scaled_features,epoch):\n",
    "    batch_idx = 0\n",
    "    for row in range(len(torch.from_numpy(columns_df).float())):\n",
    "        features = torch.from_numpy(columns_df).float()[row]\n",
    "        price = torch.FloatTensor(scaled_features['topic_num'].tolist())[row]\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            image = image.cuda()\n",
    "            features = features.cuda()\n",
    "            \n",
    "        output = model(features)\n",
    "        output = output.reshape(5)\n",
    "        loss = loss_func(output, price)\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [38]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# train \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     train(columns_df,scaled_features,epoch)\n",
      "Cell \u001b[0;32mIn[77], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(columns_df, scaled_features, epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m     image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      9\u001b[0m     features \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m---> 11\u001b[0m output \u001b[39m=\u001b[39m model(features)\n\u001b[1;32m     12\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mreshape(\u001b[39m5\u001b[39m)\n\u001b[1;32m     13\u001b[0m loss \u001b[39m=\u001b[39m loss_func(output, price)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1480\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1481\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1483\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[46], line 11\u001b[0m, in \u001b[0;36mConvolutionalNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 11\u001b[0m   x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x))\n\u001b[1;32m     12\u001b[0m   x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x))\n\u001b[1;32m     13\u001b[0m   x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x))\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1480\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1481\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1483\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [38]"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    # train \n",
    "    train(columns_df,scaled_features,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63be3639594356bc87fe58051c1d1c5221c23a964c31c0e05d208c4974bedf26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
