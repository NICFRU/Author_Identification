{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from ast import literal_eval\n",
    "import sklearn as sk\n",
    "import seaborn as sb\n",
    "import re, string\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "#import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_in_one(text):\n",
    "#     text = text.lower()\n",
    "#     text = text.strip()\n",
    "#     text = re.compile('<.*?>').sub('', text) \n",
    "#     text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "#     text = re.sub('\\s+', ' ', text)  \n",
    "#     text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "#     text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "#     text = re.sub(r'\\d',' ',text) \n",
    "#     text = re.sub(r'\\s+',' ',text) \n",
    "#     return text\n",
    "\n",
    "# def remove_stopwords(text):\n",
    "#     new_text = [word for word in text.split() if word not in stopwords.words(\"english\")]\n",
    "#     return ' '.join(new_text)\n",
    "\n",
    "# def lemmatize_text(text):\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#     # Hilfsfunktion um PosTags zu mappen\n",
    "#     def get_wordnet_pos(tag):\n",
    "#         if tag.startswith('J'):\n",
    "#             return wordnet.ADJ\n",
    "#         elif tag.startswith('V'):\n",
    "#             return wordnet.VERB\n",
    "#         elif tag.startswith('N'):\n",
    "#             return wordnet.NOUN\n",
    "#         elif tag.startswith('R'):\n",
    "#             return wordnet.ADV\n",
    "#         else:\n",
    "#             return wordnet.NOUN\n",
    "    \n",
    "#     pos_tags = nltk.pos_tag(word_tokenize(text))\n",
    "#     new_text = [lemmatizer.lemmatize(tag[0], get_wordnet_pos(tag[1])) for index, tag in enumerate(pos_tags)]\n",
    "#     return \" \".join(new_text)\n",
    "    \n",
    "# def combined_processing(text):\n",
    "#     return lemmatize_text(remove_stopwords(preprocess_in_one(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This blog is being posted due to the fact that...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>Student</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>blog post due fact little development happen r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>So I have a big fucking interview tomorrow for...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>big fucking interview tomorrow new school also...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I was reminded just now of the time Ashley and...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>reminded time ashley drove kemah windows take ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I was checking up on my cousin Dylan and Fanni...</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>check cousin dylan fannie wed site get married...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>for the NME interview click urlLink part 1 and...</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>nme interview click urllink part urllink part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Like a certain friend of mine who shant be nam...</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>Student</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>like certain friend mine shant name spit bfs m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Chloe was almost lost today. SADNESS. My mom c...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Libra</td>\n",
       "      <td>chloe almost lose today sadness mom come grand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>I am now officially old enough to get a permit...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>officially old enough get permit even though a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>capture the flag: sounds good me and kassovic ...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Libra</td>\n",
       "      <td>capture flag sound good kassovic need back go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Yes School is out for summer The sun is shinin...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>yes school summer sun shin life great happy we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>hey does anyone wanna see a movie these next f...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>hey anyone wan na see movie next five day orla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Went to Mid Valley Mega Mall today. Finally I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>go mid valley mega mall today finally watch va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Hey gurl... I'm not the best of persons to rea...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>hey gurl best person really say anything give ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>I hate being told what I can't do. It makes me...</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>hate tell make angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>For a good while now I've been in league with ...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>good league black black rhode island want take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>'For Love' I thought that I could do this I th...</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Aries</td>\n",
       "      <td>love thought could think could make see found ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Yep it was definetly OConnor. I asked him if h...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>yep definetly oconnor ask give shit bad stuff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Laura Im sorry. I meant to apologize around 2 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Libra</td>\n",
       "      <td>laura im sorry mean apologize around day ago w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Since this is a crappy blog I added it to the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>Student</td>\n",
       "      <td>Aries</td>\n",
       "      <td>since crappy blog add crappy blog webring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>BOOP BOOP BE DOOP That's all I have to say.</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>boop boop doop say</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                               text  gender  \\\n",
       "0            0  This blog is being posted due to the fact that...       1   \n",
       "1            1  So I have a big fucking interview tomorrow for...       1   \n",
       "2            2  I was reminded just now of the time Ashley and...       2   \n",
       "3            3  I was checking up on my cousin Dylan and Fanni...       2   \n",
       "4            4  for the NME interview click urlLink part 1 and...       2   \n",
       "5            5  Like a certain friend of mine who shant be nam...       2   \n",
       "6            6  Chloe was almost lost today. SADNESS. My mom c...       2   \n",
       "7            7  I am now officially old enough to get a permit...       1   \n",
       "8            8  capture the flag: sounds good me and kassovic ...       2   \n",
       "9            9  Yes School is out for summer The sun is shinin...       2   \n",
       "10          10  hey does anyone wanna see a movie these next f...       1   \n",
       "11          11  Went to Mid Valley Mega Mall today. Finally I ...       1   \n",
       "12          12  Hey gurl... I'm not the best of persons to rea...       2   \n",
       "13          13  I hate being told what I can't do. It makes me...       2   \n",
       "14          14  For a good while now I've been in league with ...       2   \n",
       "15          15  'For Love' I thought that I could do this I th...       2   \n",
       "16          16  Yep it was definetly OConnor. I asked him if h...       1   \n",
       "17          17  Laura Im sorry. I meant to apologize around 2 ...       2   \n",
       "18          18  Since this is a crappy blog I added it to the ...       2   \n",
       "19          19        BOOP BOOP BE DOOP That's all I have to say.       2   \n",
       "\n",
       "    age    topic         sign  \\\n",
       "0    14  Student  Sagittarius   \n",
       "1    15  Student       Pisces   \n",
       "2    17  Student       Gemini   \n",
       "3    23  Student       Taurus   \n",
       "4    23  Student     Aquarius   \n",
       "5    14  Student      Scorpio   \n",
       "6    16  Student        Libra   \n",
       "7    15  Student    Capricorn   \n",
       "8    17  Student        Libra   \n",
       "9    17  Student          Leo   \n",
       "10   15  Student       Gemini   \n",
       "11   17  Student       Pisces   \n",
       "12   17  Student    Capricorn   \n",
       "13   15  Student        Virgo   \n",
       "14   16  Student       Cancer   \n",
       "15   23  Student        Aries   \n",
       "16   15  Student          Leo   \n",
       "17   17  Student        Libra   \n",
       "18   33  Student        Aries   \n",
       "19   17  Student       Pisces   \n",
       "\n",
       "                                    preprocessed_text  \n",
       "0   blog post due fact little development happen r...  \n",
       "1   big fucking interview tomorrow new school also...  \n",
       "2   reminded time ashley drove kemah windows take ...  \n",
       "3   check cousin dylan fannie wed site get married...  \n",
       "4       nme interview click urllink part urllink part  \n",
       "5   like certain friend mine shant name spit bfs m...  \n",
       "6   chloe almost lose today sadness mom come grand...  \n",
       "7   officially old enough get permit even though a...  \n",
       "8   capture flag sound good kassovic need back go ...  \n",
       "9   yes school summer sun shin life great happy we...  \n",
       "10  hey anyone wan na see movie next five day orla...  \n",
       "11  go mid valley mega mall today finally watch va...  \n",
       "12  hey gurl best person really say anything give ...  \n",
       "13                               hate tell make angry  \n",
       "14  good league black black rhode island want take...  \n",
       "15  love thought could think could make see found ...  \n",
       "16  yep definetly oconnor ask give shit bad stuff ...  \n",
       "17  laura im sorry mean apologize around day ago w...  \n",
       "18          since crappy blog add crappy blog webring  \n",
       "19                                 boop boop doop say  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data[\"preprocessed_text\"] = data[\"text\"].apply(lambda text: combined_processing(text))\n",
    "data.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"gender\"\n",
    "test_size = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"preprocessed_text\"], data[target], test_size=test_size,shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "X_train_vectors = vectorizer.fit_transform(X_train.astype('U'))\n",
    "X_test_vectors = vectorizer.transform(X_test.astype('U'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "nb = MultinomialNB()\n",
    "rf = RandomForestClassifier(max_depth=15, n_estimators=150)\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Fitted\n",
      "NB Fitted\n",
      "RF Fitted\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_vectors, y_train)\n",
    "print(\"LR Fitted\")\n",
    "\n",
    "nb.fit(X_train_vectors, y_train)\n",
    "print(\"NB Fitted\")\n",
    "\n",
    "rf.fit(X_train_vectors, y_train)\n",
    "print(\"RF Fitted\")\n",
    "\n",
    "# svm.fit(X_train_vectors, y_train)\n",
    "# print(\"SVM Fitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Logistic Regression----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.80      0.75      2221\n",
      "           2       0.67      0.55      0.61      1679\n",
      "\n",
      "    accuracy                           0.69      3900\n",
      "   macro avg       0.69      0.67      0.68      3900\n",
      "weighted avg       0.69      0.69      0.69      3900\n",
      "\n",
      "----------------Naive Bayes----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.90      0.77      2221\n",
      "           2       0.75      0.40      0.52      1679\n",
      "\n",
      "    accuracy                           0.68      3900\n",
      "   macro avg       0.71      0.65      0.64      3900\n",
      "weighted avg       0.70      0.68      0.66      3900\n",
      "\n",
      "----------------Random Forest----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.96      0.74      2221\n",
      "           2       0.73      0.14      0.24      1679\n",
      "\n",
      "    accuracy                           0.61      3900\n",
      "   macro avg       0.67      0.55      0.49      3900\n",
      "weighted avg       0.66      0.61      0.52      3900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr = lr.predict(X_test_vectors)\n",
    "y_pred_nb = nb.predict(X_test_vectors)\n",
    "y_pred_rf = rf.predict(X_test_vectors)\n",
    "\n",
    "print(\"----------------Logistic Regression----------------\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "print(\"----------------Naive Bayes----------------\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "print(\"----------------Random Forest----------------\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1767,  454],\n",
       "       [ 749,  930]], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2004,  217],\n",
       "       [1014,  665]], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2134,   87],\n",
       "       [1439,  240]], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_rf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = [\"lbfgs\", \"sag\", \"saga\", \"newton-cg\", \"liblinear\"]\n",
    "penalties = [\"l1\", \"l2\", \"elasticnet\", \"none\"]\n",
    "c_values = [0.001, 0.01, 0.1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:06<00:24,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:13<00:20,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:39<02:20, 70.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:55<00:00, 35.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c_list = []\n",
    "solver_list = []\n",
    "penalty_list = []\n",
    "acc_list = []\n",
    "\n",
    "for solver in tqdm(solvers):\n",
    "    for penalty in penalties:\n",
    "        for c in c_values:\n",
    "            try:\n",
    "                lr = LogisticRegression(solver=solver, penalty=penalty, C=c)\n",
    "                lr.fit(X_train_vectors, y_train)\n",
    "                preds = lr.predict(X_test_vectors)\n",
    "\n",
    "                solver_list.append(solver)\n",
    "                penalty_list.append(penalty)\n",
    "                c_list.append(c)\n",
    "                acc_list.append(accuracy_score(y_test, preds))\n",
    "            except(ValueError):\n",
    "                print(\"-----ValueError------\")\n",
    "            \n",
    "data_log = pd.DataFrame({\"Solver\": solver_list, \"Penalty\": penalty_list, \"C\": c_list, \"Accuracy\": acc_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Solver</th>\n",
       "      <th>Penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.691538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sag</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.691538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.691538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>liblinear</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.691538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>newton-cg</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.691538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sag</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.569487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.569487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.569487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.569487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.569487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Solver Penalty      C  Accuracy\n",
       "33       saga      l2  1.000  0.691538\n",
       "15        sag      l2  1.000  0.691538\n",
       "3       lbfgs      l2  1.000  0.691538\n",
       "63  liblinear      l2  1.000  0.691538\n",
       "45  newton-cg      l2  1.000  0.691538\n",
       "..        ...     ...    ...       ...\n",
       "12        sag      l2  0.001  0.569487\n",
       "30       saga      l2  0.001  0.569487\n",
       "25       saga      l1  0.010  0.569487\n",
       "24       saga      l1  0.001  0.569487\n",
       "0       lbfgs      l2  0.001  0.569487\n",
       "\n",
       "[66 rows x 4 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_log.sort_values(by=\"Accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"results/results_gender.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sternzeichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"sign\"\n",
    "test_size = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"preprocessed_text\"], data[target], test_size=test_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "X_train_vectors = vectorizer.fit_transform(X_train.astype('U'))\n",
    "X_test_vectors = vectorizer.transform(X_test.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "nb = MultinomialNB()\n",
    "rf = RandomForestClassifier(max_depth=15, n_estimators=150)\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Fitted\n",
      "NB Fitted\n",
      "RF Fitted\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_vectors, y_train)\n",
    "print(\"LR Fitted\")\n",
    "\n",
    "nb.fit(X_train_vectors, y_train)\n",
    "print(\"NB Fitted\")\n",
    "\n",
    "rf.fit(X_train_vectors, y_train)\n",
    "print(\"RF Fitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Logistic Regression----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Aquarius       0.15      0.10      0.12       277\n",
      "       Aries       0.21      0.24      0.23       369\n",
      "      Cancer       0.16      0.26      0.20       362\n",
      "   Capricorn       0.24      0.11      0.15       257\n",
      "      Gemini       0.26      0.17      0.21       315\n",
      "         Leo       0.20      0.15      0.17       314\n",
      "       Libra       0.23      0.22      0.23       325\n",
      "      Pisces       0.22      0.24      0.23       365\n",
      " Sagittarius       0.35      0.20      0.25       310\n",
      "     Scorpio       0.19      0.23      0.21       367\n",
      "      Taurus       0.16      0.18      0.17       315\n",
      "       Virgo       0.17      0.26      0.21       324\n",
      "\n",
      "    accuracy                           0.20      3900\n",
      "   macro avg       0.21      0.20      0.20      3900\n",
      "weighted avg       0.21      0.20      0.20      3900\n",
      "\n",
      "----------------Naive Bayes----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Aquarius       0.60      0.02      0.04       277\n",
      "       Aries       0.23      0.25      0.24       369\n",
      "      Cancer       0.11      0.62      0.19       362\n",
      "   Capricorn       1.00      0.00      0.01       257\n",
      "      Gemini       0.69      0.03      0.07       315\n",
      "         Leo       0.44      0.03      0.05       314\n",
      "       Libra       0.40      0.10      0.16       325\n",
      "      Pisces       0.29      0.21      0.24       365\n",
      " Sagittarius       0.82      0.07      0.14       310\n",
      "     Scorpio       0.19      0.20      0.20       367\n",
      "      Taurus       0.37      0.13      0.19       315\n",
      "       Virgo       0.15      0.27      0.19       324\n",
      "\n",
      "    accuracy                           0.17      3900\n",
      "   macro avg       0.44      0.16      0.14      3900\n",
      "weighted avg       0.42      0.17      0.15      3900\n",
      "\n",
      "----------------Random Forest----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Aquarius       0.86      0.02      0.04       277\n",
      "       Aries       0.29      0.17      0.22       369\n",
      "      Cancer       0.10      0.82      0.19       362\n",
      "   Capricorn       0.00      0.00      0.00       257\n",
      "      Gemini       0.88      0.05      0.09       315\n",
      "         Leo       0.50      0.03      0.06       314\n",
      "       Libra       0.47      0.09      0.15       325\n",
      "      Pisces       0.32      0.18      0.23       365\n",
      " Sagittarius       0.66      0.13      0.21       310\n",
      "     Scorpio       0.22      0.13      0.16       367\n",
      "      Taurus       0.35      0.07      0.12       315\n",
      "       Virgo       0.23      0.13      0.17       324\n",
      "\n",
      "    accuracy                           0.16      3900\n",
      "   macro avg       0.41      0.15      0.14      3900\n",
      "weighted avg       0.40      0.16      0.14      3900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr = lr.predict(X_test_vectors)\n",
    "y_pred_nb = nb.predict(X_test_vectors)\n",
    "y_pred_rf = rf.predict(X_test_vectors)\n",
    "\n",
    "print(\"----------------Logistic Regression----------------\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "print(\"----------------Naive Bayes----------------\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "print(\"----------------Random Forest----------------\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = [\"lbfgs\", \"sag\", \"saga\", \"newton-cg\", \"liblinear\"]\n",
    "penalties = [\"l1\", \"l2\", \"elasticnet\", \"none\"]\n",
    "c_values = [0.001, 0.01, 0.1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:13<04:53, 73.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:47<02:31, 50.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [12:54<11:03, 331.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [25:23<00:00, 304.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n",
      "-----ValueError------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c_list = []\n",
    "solver_list = []\n",
    "penalty_list = []\n",
    "acc_list = []\n",
    "\n",
    "for solver in tqdm(solvers):\n",
    "    for penalty in penalties:\n",
    "        for c in c_values:\n",
    "            try:\n",
    "                lr = LogisticRegression(solver=solver, penalty=penalty, C=c)\n",
    "                lr.fit(X_train_vectors, y_train)\n",
    "                preds = lr.predict(X_test_vectors)\n",
    "\n",
    "                solver_list.append(solver)\n",
    "                penalty_list.append(penalty)\n",
    "                c_list.append(c)\n",
    "                acc_list.append(accuracy_score(y_test, preds))\n",
    "            except(ValueError):\n",
    "                print(\"-----ValueError------\")\n",
    "            \n",
    "data_log = pd.DataFrame({\"Solver\": solver_list, \"Penalty\": penalty_list, \"C\": c_list, \"Accuracy\": acc_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Solver</th>\n",
       "      <th>Penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.209487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>liblinear</td>\n",
       "      <td>l2</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.209231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>liblinear</td>\n",
       "      <td>l2</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.207692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.207436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>liblinear</td>\n",
       "      <td>l1</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.206154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>newton-cg</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.092821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.092821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.092821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.092821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.092821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Solver Penalty        C  Accuracy\n",
       "28       saga      l1   10.000  0.209487\n",
       "64  liblinear      l2   10.000  0.209231\n",
       "65  liblinear      l2  100.000  0.207692\n",
       "4       lbfgs      l2   10.000  0.207436\n",
       "58  liblinear      l1   10.000  0.206154\n",
       "..        ...     ...      ...       ...\n",
       "42  newton-cg      l2    0.001  0.092821\n",
       "24       saga      l1    0.001  0.092821\n",
       "25       saga      l1    0.010  0.092821\n",
       "30       saga      l2    0.001  0.092821\n",
       "0       lbfgs      l2    0.001  0.092821\n",
       "\n",
       "[66 rows x 4 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_log.sort_values(by=\"Accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"results/results_sternzeichen.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP-New",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06972781760676f1ec39ca0dd490c0cce4e321933a34cdf9140b46909a4aadfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
