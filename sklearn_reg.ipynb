{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age Prediction mit Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_reg.csv\")\n",
    "df_vali = pd.read_csv(\"vali_reg.csv\")\n",
    "df_test = pd.read_csv(\"test_reg.csv\")\n",
    "\n",
    "df_train.labels  = df_train.labels.apply(str)\n",
    "df_vali.labels  = df_vali.labels.apply(str)\n",
    "df_test.labels  = df_test.labels.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/constantin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"html.parser\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "    \n",
    "df_train['text'] = df_train['text'].apply(clean_text)\n",
    "df_vali['text'] = df_vali['text'].apply(clean_text)\n",
    "df_test['text'] = df_test['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train['text']\n",
    "y_train = df_train['labels']\n",
    "x_test = df_vali['text']\n",
    "y_test = df_vali['labels']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvecpipe = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('prevec',\n",
       "                                        Pipeline(steps=[('vect',\n",
       "                                                         CountVectorizer()),\n",
       "                                                        ('tfidf',\n",
       "                                                         TfidfTransformer())])),\n",
       "                                       ('model', LinearSVR(random_state=42))]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'model__loss': ['epsilon_insensitive',\n",
       "                                         'squared_epsilon_insensitive'],\n",
       "                         'model__max_iter': [1000, 1500, 500],\n",
       "                         'model__tol': [0.0001, 1e-05, 0.001]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('prevec',wordvecpipe),\n",
    "    ('model', LinearSVR(random_state=RANDOM_SEED))\n",
    "])\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe, \n",
    "    param_grid={\n",
    "        'model__loss': ['epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "        'model__max_iter': [1000,1500,500],\n",
    "        'model__tol':[1e-4,1e-5,1e-3]\n",
    "    }, \n",
    "    cv=10,\n",
    "    n_jobs=4,\n",
    "    verbose=0, # Für volle Information auf 4 ändern\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    refit=True\n",
    ")\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters: {'model__loss': 'squared_epsilon_insensitive', 'model__max_iter': 1000, 'model__tol': 1e-05}\n",
      "Best score: -9.535863286085455\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best model parameters: {grid.best_params_}\")\n",
    "print(f\"Best score: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 8.746632022057026\n",
      "R2: 0.09086570066623523\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(x_test)\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R2: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('prevec',\n",
       "                                        Pipeline(steps=[('vect',\n",
       "                                                         CountVectorizer()),\n",
       "                                                        ('tfidf',\n",
       "                                                         TfidfTransformer())])),\n",
       "                                       ('model',\n",
       "                                        DecisionTreeRegressor(random_state=42))]),\n",
       "             n_jobs=1,\n",
       "             param_grid={'model__max_depth': [2, 5, 10],\n",
       "                         'model__splitter': ['best', 'random']},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('prevec',wordvecpipe),\n",
    "    ('model', DecisionTreeRegressor(random_state=RANDOM_SEED))\n",
    "])\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe, \n",
    "    param_grid={'model__max_depth': [2, 5, 10],\n",
    "                'model__splitter' : [\"best\", \"random\"]\n",
    "                               },\n",
    "    cv=10,\n",
    "    n_jobs=1,\n",
    "    verbose=0,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    refit=True\n",
    ")\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters: {'model__max_depth': 10, 'model__splitter': 'best'}\n",
      "Best score: -10.198425903441077\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best model parameters: {grid.best_params_}\")\n",
    "print(f\"Best score: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 9.214151171899976\n",
      "R2: 0.05079540636522706\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(x_test)\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R2: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 2/5] END model__max_depth=2, model__n_estimators=200;, score=-12.900 total time=   8.8s\n",
      "[CV 1/5] END model__max_depth=2, model__n_estimators=200;, score=-7.544 total time=   9.3s\n",
      "[CV 3/5] END model__max_depth=2, model__n_estimators=200;, score=-10.314 total time=   8.2s\n",
      "[CV 4/5] END model__max_depth=2, model__n_estimators=200;, score=-9.687 total time=   8.7s\n",
      "[CV 5/5] END model__max_depth=2, model__n_estimators=200;, score=-14.704 total time=   8.5s\n",
      "[CV 1/5] END model__max_depth=2, model__n_estimators=300;, score=-7.545 total time=  11.7s\n",
      "[CV 2/5] END model__max_depth=2, model__n_estimators=300;, score=-12.903 total time=  10.0s\n",
      "[CV 3/5] END model__max_depth=2, model__n_estimators=300;, score=-10.316 total time=  10.3s\n",
      "[CV 4/5] END model__max_depth=2, model__n_estimators=300;, score=-9.689 total time=  10.8s\n",
      "[CV 5/5] END model__max_depth=2, model__n_estimators=300;, score=-14.702 total time=  10.7s\n",
      "[CV 1/5] END model__max_depth=5, model__n_estimators=200;, score=-7.483 total time=  19.0s\n",
      "[CV 2/5] END model__max_depth=5, model__n_estimators=200;, score=-12.739 total time=  17.9s\n",
      "[CV 3/5] END model__max_depth=5, model__n_estimators=200;, score=-10.151 total time=  17.6s\n",
      "[CV 4/5] END model__max_depth=5, model__n_estimators=200;, score=-9.607 total time=  19.5s\n",
      "[CV 5/5] END model__max_depth=5, model__n_estimators=200;, score=-14.590 total time=  19.8s\n",
      "[CV 1/5] END model__max_depth=5, model__n_estimators=300;, score=-7.484 total time=  28.3s\n",
      "[CV 2/5] END model__max_depth=5, model__n_estimators=300;, score=-12.735 total time=  26.6s\n",
      "[CV 3/5] END model__max_depth=5, model__n_estimators=300;, score=-10.151 total time=  26.1s\n",
      "[CV 4/5] END model__max_depth=5, model__n_estimators=300;, score=-9.604 total time=  29.3s\n",
      "[CV 5/5] END model__max_depth=5, model__n_estimators=300;, score=-14.584 total time=  30.1s\n",
      "[CV 1/5] END model__max_depth=10, model__n_estimators=200;, score=-7.422 total time=  44.9s\n",
      "[CV 2/5] END model__max_depth=10, model__n_estimators=200;, score=-12.609 total time=  39.9s\n",
      "[CV 3/5] END model__max_depth=10, model__n_estimators=200;, score=-10.034 total time=  42.8s\n",
      "[CV 4/5] END model__max_depth=10, model__n_estimators=200;, score=-9.595 total time=  50.9s\n",
      "[CV 5/5] END model__max_depth=10, model__n_estimators=200;, score=-14.539 total time=  51.3s\n",
      "[CV 1/5] END model__max_depth=10, model__n_estimators=300;, score=-7.425 total time= 1.4min\n",
      "[CV 2/5] END model__max_depth=10, model__n_estimators=300;, score=-12.605 total time= 1.2min\n",
      "[CV 3/5] END model__max_depth=10, model__n_estimators=300;, score=-10.032 total time= 1.0min\n",
      "[CV 4/5] END model__max_depth=10, model__n_estimators=300;, score=-9.591 total time= 1.2min\n",
      "[CV 5/5] END model__max_depth=10, model__n_estimators=300;, score=-14.534 total time= 1.2min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('prevec',\n",
       "                                        Pipeline(steps=[('vect',\n",
       "                                                         CountVectorizer()),\n",
       "                                                        ('tfidf',\n",
       "                                                         TfidfTransformer())])),\n",
       "                                       ('model',\n",
       "                                        RandomForestRegressor(random_state=42))]),\n",
       "             n_jobs=2,\n",
       "             param_grid={'model__max_depth': [2, 5, 10],\n",
       "                         'model__n_estimators': [200, 300]},\n",
       "             scoring='neg_mean_absolute_error', verbose=4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('prevec',wordvecpipe),\n",
    "    ('model', RandomForestRegressor(random_state=RANDOM_SEED))\n",
    "])\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe, \n",
    "    param_grid={\n",
    "                'model__max_depth':[2,5,10],\n",
    "                'model__n_estimators':[200,300]\n",
    "                },\n",
    "    cv=5,\n",
    "    n_jobs=2,\n",
    "    verbose=4,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    refit=True\n",
    ")\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters: {'model__max_depth': 10, 'model__n_estimators': 300}\n",
      "Best score: -10.83743950589\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best model parameters: {grid.best_params_}\")\n",
    "print(f\"Best score: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 9.181644862613082\n",
      "R2: 0.07840671883118888\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(x_test)\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R2: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 2/5] END model__learning_rate=0.01, model__n_estimators=2000;, score=-15.374 total time= 2.3min\n",
      "[CV 1/5] END model__learning_rate=0.01, model__n_estimators=2000;, score=-9.943 total time= 2.5min\n",
      "[CV 3/5] END model__learning_rate=0.01, model__n_estimators=2000;, score=-10.950 total time= 2.7min\n",
      "[CV 4/5] END model__learning_rate=0.01, model__n_estimators=2000;, score=-8.007 total time= 2.8min\n",
      "[CV 1/5] END model__learning_rate=0.01, model__n_estimators=1500;, score=-9.943 total time= 2.0min\n",
      "[CV 5/5] END model__learning_rate=0.01, model__n_estimators=2000;, score=-11.994 total time= 2.5min\n",
      "[CV 2/5] END model__learning_rate=0.01, model__n_estimators=1500;, score=-15.374 total time= 1.9min\n",
      "[CV 3/5] END model__learning_rate=0.01, model__n_estimators=1500;, score=-10.952 total time= 1.9min\n",
      "[CV 4/5] END model__learning_rate=0.01, model__n_estimators=1500;, score=-8.007 total time= 1.9min\n",
      "[CV 5/5] END model__learning_rate=0.01, model__n_estimators=1500;, score=-11.994 total time= 1.9min\n",
      "[CV 2/5] END model__learning_rate=1e-25, model__n_estimators=2000;, score=-15.868 total time= 2.6min\n",
      "[CV 1/5] END model__learning_rate=1e-25, model__n_estimators=2000;, score=-10.489 total time= 2.8min\n",
      "[CV 3/5] END model__learning_rate=1e-25, model__n_estimators=2000;, score=-11.233 total time= 2.5min\n",
      "[CV 4/5] END model__learning_rate=1e-25, model__n_estimators=2000;, score=-7.719 total time= 2.6min\n",
      "[CV 1/5] END model__learning_rate=1e-25, model__n_estimators=1500;, score=-10.489 total time= 1.8min\n",
      "[CV 5/5] END model__learning_rate=1e-25, model__n_estimators=2000;, score=-11.527 total time= 2.3min\n",
      "[CV 2/5] END model__learning_rate=1e-25, model__n_estimators=1500;, score=-15.868 total time= 1.7min\n",
      "[CV 3/5] END model__learning_rate=1e-25, model__n_estimators=1500;, score=-11.233 total time= 1.7min\n",
      "[CV 4/5] END model__learning_rate=1e-25, model__n_estimators=1500;, score=-7.719 total time= 1.8min\n",
      "[CV 5/5] END model__learning_rate=1e-25, model__n_estimators=1500;, score=-11.527 total time= 1.7min\n",
      "[CV 1/5] END model__learning_rate=1e-15, model__n_estimators=2000;, score=-10.489 total time= 2.3min\n",
      "[CV 2/5] END model__learning_rate=1e-15, model__n_estimators=2000;, score=-15.868 total time= 2.2min\n",
      "[CV 3/5] END model__learning_rate=1e-15, model__n_estimators=2000;, score=-11.233 total time= 2.1min\n",
      "[CV 4/5] END model__learning_rate=1e-15, model__n_estimators=2000;, score=-7.719 total time= 2.3min\n",
      "[CV 1/5] END model__learning_rate=1e-15, model__n_estimators=1500;, score=-10.489 total time= 1.9min\n",
      "[CV 5/5] END model__learning_rate=1e-15, model__n_estimators=2000;, score=-11.527 total time= 2.5min\n",
      "[CV 2/5] END model__learning_rate=1e-15, model__n_estimators=1500;, score=-15.868 total time= 2.0min\n",
      "[CV 3/5] END model__learning_rate=1e-15, model__n_estimators=1500;, score=-11.233 total time= 2.0min\n",
      "[CV 4/5] END model__learning_rate=1e-15, model__n_estimators=1500;, score=-7.719 total time= 1.8min\n",
      "[CV 5/5] END model__learning_rate=1e-15, model__n_estimators=1500;, score=-11.527 total time= 1.8min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('prevec',\n",
       "                                        Pipeline(steps=[('vect',\n",
       "                                                         CountVectorizer()),\n",
       "                                                        ('tfidf',\n",
       "                                                         TfidfTransformer())])),\n",
       "                                       ('model',\n",
       "                                        GradientBoostingRegressor(loss='absolute_error',\n",
       "                                                                  random_state=42))]),\n",
       "             n_jobs=2,\n",
       "             param_grid={'model__learning_rate': [0.01, 1e-25, 1e-15],\n",
       "                         'model__n_estimators': [2000, 1500]},\n",
       "             scoring='neg_mean_absolute_error', verbose=4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('prevec',wordvecpipe),\n",
    "    ('model', GradientBoostingRegressor(random_state=RANDOM_SEED,loss='absolute_error'))\n",
    "])\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe, \n",
    "    param_grid={'model__n_estimators': [2000, 1500],\n",
    "                                'model__learning_rate' : [1e-2, 1e-25,1e-15],\n",
    "                               },\n",
    "    cv=5,\n",
    "    n_jobs=2,\n",
    "    verbose=4,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    refit=True\n",
    ")\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters: {'model__learning_rate': 0.01, 'model__n_estimators': 2000}\n",
      "Best score: -11.253634301522919\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best model parameters: {grid.best_params_}\")\n",
    "print(f\"Best score: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 9.110828517691774\n",
      "R2: -0.010039765900544007\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(x_test)\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R2: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END model__max_depth=2, model__n_estimators=2000;, score=-9.652 total time=  57.1s\n",
      "[CV 1/5] END model__max_depth=2, model__n_estimators=2000;, score=-7.992 total time=  57.3s\n",
      "[CV 2/5] END model__max_depth=2, model__n_estimators=2000;, score=-11.676 total time=  57.3s\n",
      "[CV 4/5] END model__max_depth=2, model__n_estimators=2000;, score=-8.795 total time=  56.0s\n",
      "[CV 5/5] END model__max_depth=2, model__n_estimators=2000;, score=-13.787 total time=  56.1s\n",
      "[CV 1/5] END model__max_depth=2, model__n_estimators=2500;, score=-8.093 total time= 1.1min\n",
      "[CV 3/5] END model__max_depth=2, model__n_estimators=2500;, score=-9.683 total time= 1.1min\n",
      "[CV 2/5] END model__max_depth=2, model__n_estimators=2500;, score=-11.692 total time= 1.1min\n",
      "[CV 4/5] END model__max_depth=2, model__n_estimators=2500;, score=-8.764 total time= 1.2min\n",
      "[CV 5/5] END model__max_depth=2, model__n_estimators=2500;, score=-13.723 total time= 1.2min\n",
      "[CV 1/5] END model__max_depth=5, model__n_estimators=2000;, score=-8.560 total time= 2.1min\n",
      "[CV 2/5] END model__max_depth=5, model__n_estimators=2000;, score=-11.778 total time= 2.1min\n",
      "[CV 3/5] END model__max_depth=5, model__n_estimators=2000;, score=-10.011 total time= 2.1min\n",
      "[CV 4/5] END model__max_depth=5, model__n_estimators=2000;, score=-8.896 total time= 2.2min\n",
      "[CV 5/5] END model__max_depth=5, model__n_estimators=2000;, score=-13.662 total time= 2.2min\n",
      "[CV 1/5] END model__max_depth=5, model__n_estimators=2500;, score=-8.657 total time= 2.7min\n",
      "[CV 2/5] END model__max_depth=5, model__n_estimators=2500;, score=-11.798 total time= 2.7min\n",
      "[CV 3/5] END model__max_depth=5, model__n_estimators=2500;, score=-10.091 total time= 2.6min\n",
      "[CV 4/5] END model__max_depth=5, model__n_estimators=2500;, score=-8.901 total time= 2.6min\n",
      "[CV 5/5] END model__max_depth=5, model__n_estimators=2500;, score=-13.646 total time= 2.6min\n",
      "[CV 1/5] END model__max_depth=10, model__n_estimators=2000;, score=-9.038 total time= 4.1min\n",
      "[CV 2/5] END model__max_depth=10, model__n_estimators=2000;, score=-11.875 total time= 4.1min\n",
      "[CV 3/5] END model__max_depth=10, model__n_estimators=2000;, score=-10.302 total time= 4.0min\n",
      "[CV 4/5] END model__max_depth=10, model__n_estimators=2000;, score=-8.985 total time= 4.1min\n",
      "[CV 5/5] END model__max_depth=10, model__n_estimators=2000;, score=-13.639 total time= 4.1min\n",
      "[CV 1/5] END model__max_depth=10, model__n_estimators=2500;, score=-9.146 total time= 5.2min\n",
      "[CV 2/5] END model__max_depth=10, model__n_estimators=2500;, score=-11.911 total time= 5.4min\n",
      "[CV 3/5] END model__max_depth=10, model__n_estimators=2500;, score=-10.363 total time= 5.3min\n",
      "[CV 4/5] END model__max_depth=10, model__n_estimators=2500;, score=-9.037 total time= 4.9min\n",
      "[CV 5/5] END model__max_depth=10, model__n_estimators=2500;, score=-13.642 total time= 3.7min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('prevec',\n",
       "                                        Pipeline(steps=[('vect',\n",
       "                                                         CountVectorizer()),\n",
       "                                                        ('tfidf',\n",
       "                                                         TfidfTransformer())])),\n",
       "                                       ('model',\n",
       "                                        XGBRegressor(base_score=None,\n",
       "                                                     booster=None,\n",
       "                                                     colsample_bylevel=None,\n",
       "                                                     colsample_bynode=None,\n",
       "                                                     colsample_bytree=None,\n",
       "                                                     enable_categorical=False,\n",
       "                                                     gamma=None, gpu_id=None,\n",
       "                                                     importance_type=None,\n",
       "                                                     interaction_constraints=None,\n",
       "                                                     learn...\n",
       "                                                     monotone_constraints=None,\n",
       "                                                     n_estimators=100,\n",
       "                                                     n_jobs=None,\n",
       "                                                     num_parallel_tree=None,\n",
       "                                                     predictor=None,\n",
       "                                                     random_state=None,\n",
       "                                                     reg_alpha=None,\n",
       "                                                     reg_lambda=None,\n",
       "                                                     scale_pos_weight=None,\n",
       "                                                     subsample=None,\n",
       "                                                     tree_method=None,\n",
       "                                                     validate_parameters=None,\n",
       "                                                     verbosity=None))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'model__max_depth': [2, 5, 10],\n",
       "                         'model__n_estimators': [2000, 2500]},\n",
       "             scoring='neg_mean_absolute_error', verbose=4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('prevec',wordvecpipe),\n",
    "    ('model', XGBRegressor())\n",
    "])\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe, \n",
    "    param_grid={'model__n_estimators': [2000, 2500],\n",
    "                                'model__max_depth':[2,5,10]                          \n",
    "                               },\n",
    "    cv=5,\n",
    "    n_jobs=3,\n",
    "    verbose=4,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    refit=True\n",
    ")\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters: {'model__max_depth': 2, 'model__n_estimators': 2000}\n",
      "Best score: -10.380327932987623\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best model parameters: {grid.best_params_}\")\n",
    "print(f\"Best score: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 8.785981851108497\n",
      "R2: 0.12123050741159658\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(x_test)\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R2: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "rf = RandomForestRegressor(random_state=RANDOM_SEED, max_depth = 10, n_estimators= 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = StackingCVRegressor(regressors=(ridge, rf),\n",
    "                            meta_regressor=lasso)\n",
    "\n",
    "pipe = Pipeline([('prevec',wordvecpipe),('stackmodel',stack)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prevec',\n",
       "                 Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                 ('tfidf', TfidfTransformer())])),\n",
       "                ('stackmodel',\n",
       "                 StackingCVRegressor(meta_regressor=Lasso(),\n",
       "                                     regressors=(Ridge(),\n",
       "                                                 RandomForestRegressor(max_depth=10,\n",
       "                                                                       n_estimators=300,\n",
       "                                                                       random_state=42))))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 8.584477018765524\n",
      "R2: 0.15341670282035436\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(x_test)\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R2: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = LinearSVR(loss = 'squared_epsilon_insensitive', max_iter= 1000, tol= 1e-05)\n",
    "xgb = XGBRegressor(max_depth= 2, n_estimators= 2000)\n",
    "rfr = RandomForestRegressor(max_depth = 10, n_estimators = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = StackingCVRegressor(regressors=(lin, xgb),\n",
    "                            meta_regressor=rfr)\n",
    "\n",
    "pipe = Pipeline([('prevec',wordvecpipe),('stackmodel',stack)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prevec',\n",
       "                 Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                 ('tfidf', TfidfTransformer())])),\n",
       "                ('stackmodel',\n",
       "                 StackingCVRegressor(meta_regressor=RandomForestRegressor(max_depth=10,\n",
       "                                                                          n_estimators=300),\n",
       "                                     regressors=(LinearSVR(loss='squared_epsilon_insensitive',\n",
       "                                                           tol=1e-05),\n",
       "                                                 XGBRegressor(base_score=None,\n",
       "                                                              booster=None,\n",
       "                                                              colsample_bylevel=None,\n",
       "                                                              colsample_byno...\n",
       "                                                              interaction_constraints=None,\n",
       "                                                              learning_rate=None,\n",
       "                                                              max_delta_step=None,\n",
       "                                                              max_depth=2,\n",
       "                                                              min_child_weight=None,\n",
       "                                                              missing=nan,\n",
       "                                                              monotone_constraints=None,\n",
       "                                                              n_estimators=2000,\n",
       "                                                              n_jobs=None,\n",
       "                                                              num_parallel_tree=None,\n",
       "                                                              predictor=None,\n",
       "                                                              random_state=None,\n",
       "                                                              reg_alpha=None,\n",
       "                                                              reg_lambda=None,\n",
       "                                                              scale_pos_weight=None,\n",
       "                                                              subsample=None,\n",
       "                                                              tree_method=None,\n",
       "                                                              validate_parameters=None,\n",
       "                                                              verbosity=None))))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 8.523375070707397\n",
      "R2: 0.1481616207210874\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(x_test)\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R2: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Safe Model for Frontend**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reg_model.joblib']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "#dump(pipe, 'reg_model.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_joblib = joblib.load('reg_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 8.523375070707397\n",
      "R2: 0.1481616207210874\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_joblib.predict(x_test)\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R2: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'info found + 100 pages 45 mb pdf files wait untill team leader processed learns html'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.350385318226245"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_joblib.predict([x_test[0]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 10 2022, 13:17:42) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
